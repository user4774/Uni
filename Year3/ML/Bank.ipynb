{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "0       58    management   married   tertiary      no     2143     yes   no   \n",
       "1       44    technician    single  secondary      no       29     yes   no   \n",
       "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
       "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
       "4       33       unknown    single    unknown      no        1      no   no   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "45206   51    technician   married   tertiary      no      825      no   no   \n",
       "45207   71       retired  divorced    primary      no     1729      no   no   \n",
       "45208   72       retired   married  secondary      no     5715      no   no   \n",
       "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
       "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
       "0        unknown    5   may       261         1     -1         0  unknown   no  \n",
       "1        unknown    5   may       151         1     -1         0  unknown   no  \n",
       "2        unknown    5   may        76         1     -1         0  unknown   no  \n",
       "3        unknown    5   may        92         1     -1         0  unknown   no  \n",
       "4        unknown    5   may       198         1     -1         0  unknown   no  \n",
       "...          ...  ...   ...       ...       ...    ...       ...      ...  ...  \n",
       "45206   cellular   17   nov       977         3     -1         0  unknown  yes  \n",
       "45207   cellular   17   nov       456         2     -1         0  unknown  yes  \n",
       "45208   cellular   17   nov      1127         5    184         3  success  yes  \n",
       "45209  telephone   17   nov       508         4     -1         0  unknown   no  \n",
       "45210   cellular   17   nov       361         2    188        11    other   no  \n",
       "\n",
       "[45211 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.read_csv(\"bank-full.csv\", delimiter=';')\n",
    "display(df)\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>...</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>825</td>\n",
       "      <td>17</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>1729</td>\n",
       "      <td>17</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>5715</td>\n",
       "      <td>17</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>668</td>\n",
       "      <td>17</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>2971</td>\n",
       "      <td>17</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  balance  day  duration  campaign  pdays  previous  \\\n",
       "0       58     2143    5       261         1     -1         0   \n",
       "1       44       29    5       151         1     -1         0   \n",
       "2       33        2    5        76         1     -1         0   \n",
       "3       47     1506    5        92         1     -1         0   \n",
       "4       33        1    5       198         1     -1         0   \n",
       "...    ...      ...  ...       ...       ...    ...       ...   \n",
       "45206   51      825   17       977         3     -1         0   \n",
       "45207   71     1729   17       456         2     -1         0   \n",
       "45208   72     5715   17      1127         5    184         3   \n",
       "45209   57      668   17       508         4     -1         0   \n",
       "45210   37     2971   17       361         2    188        11   \n",
       "\n",
       "       poutcome_failure  poutcome_other  poutcome_success  ...  month_feb  \\\n",
       "0                     0               0                 0  ...          0   \n",
       "1                     0               0                 0  ...          0   \n",
       "2                     0               0                 0  ...          0   \n",
       "3                     0               0                 0  ...          0   \n",
       "4                     0               0                 0  ...          0   \n",
       "...                 ...             ...               ...  ...        ...   \n",
       "45206                 0               0                 0  ...          0   \n",
       "45207                 0               0                 0  ...          0   \n",
       "45208                 0               0                 1  ...          0   \n",
       "45209                 0               0                 0  ...          0   \n",
       "45210                 0               1                 0  ...          0   \n",
       "\n",
       "       month_jan  month_jul  month_jun  month_mar  month_may  month_nov  \\\n",
       "0              0          0          0          0          1          0   \n",
       "1              0          0          0          0          1          0   \n",
       "2              0          0          0          0          1          0   \n",
       "3              0          0          0          0          1          0   \n",
       "4              0          0          0          0          1          0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "45206          0          0          0          0          0          1   \n",
       "45207          0          0          0          0          0          1   \n",
       "45208          0          0          0          0          0          1   \n",
       "45209          0          0          0          0          0          1   \n",
       "45210          0          0          0          0          0          1   \n",
       "\n",
       "       month_oct  month_sep    y  \n",
       "0              0          0   no  \n",
       "1              0          0   no  \n",
       "2              0          0   no  \n",
       "3              0          0   no  \n",
       "4              0          0   no  \n",
       "...          ...        ...  ...  \n",
       "45206          0          0  yes  \n",
       "45207          0          0  yes  \n",
       "45208          0          0  yes  \n",
       "45209          0          0   no  \n",
       "45210          0          0   no  \n",
       "\n",
       "[45211 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_y = df[\"y\"]\n",
    "df = df.drop(columns=[\"y\", \"job\",\"education\", \"contact\", \"marital\", \"default\", \"housing\", \"loan\"], axis=1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"poutcome\", \"month\"]).drop([\"poutcome_unknown\"], axis=1)\n",
    "\n",
    "df['y'] = df_y\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>...</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  default  balance  housing  loan  day  duration  campaign  pdays  \\\n",
       "0       58        0     2143        1     0    5       261         1     -1   \n",
       "1       44        0       29        1     0    5       151         1     -1   \n",
       "2       33        0        2        1     1    5        76         1     -1   \n",
       "3       47        0     1506        1     0    5        92         1     -1   \n",
       "4       33        0        1        0     0    5       198         1     -1   \n",
       "...    ...      ...      ...      ...   ...  ...       ...       ...    ...   \n",
       "45206   51        0      825        0     0   17       977         3     -1   \n",
       "45207   71        0     1729        0     0   17       456         2     -1   \n",
       "45208   72        0     5715        0     0   17      1127         5    184   \n",
       "45209   57        0      668        0     0   17       508         4     -1   \n",
       "45210   37        0     2971        0     0   17       361         2    188   \n",
       "\n",
       "       previous  ...  month_feb  month_jan  month_jul  month_jun  month_mar  \\\n",
       "0             0  ...          0          0          0          0          0   \n",
       "1             0  ...          0          0          0          0          0   \n",
       "2             0  ...          0          0          0          0          0   \n",
       "3             0  ...          0          0          0          0          0   \n",
       "4             0  ...          0          0          0          0          0   \n",
       "...         ...  ...        ...        ...        ...        ...        ...   \n",
       "45206         0  ...          0          0          0          0          0   \n",
       "45207         0  ...          0          0          0          0          0   \n",
       "45208         3  ...          0          0          0          0          0   \n",
       "45209         0  ...          0          0          0          0          0   \n",
       "45210        11  ...          0          0          0          0          0   \n",
       "\n",
       "       month_may  month_nov  month_oct  month_sep    y  \n",
       "0              1          0          0          0   no  \n",
       "1              1          0          0          0   no  \n",
       "2              1          0          0          0   no  \n",
       "3              1          0          0          0   no  \n",
       "4              1          0          0          0   no  \n",
       "...          ...        ...        ...        ...  ...  \n",
       "45206          0          1          0          0  yes  \n",
       "45207          0          1          0          0  yes  \n",
       "45208          0          1          0          0  yes  \n",
       "45209          0          1          0          0   no  \n",
       "45210          0          1          0          0   no  \n",
       "\n",
       "[45211 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_y = df[\"y\"]\n",
    "df = df.drop(columns=[\"y\"], axis=1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"job\",\"education\", \"contact\" ,\"poutcome\", \"marital\", \"month\"]).drop([\"job_unknown\", \"education_unknown\", \"contact_unknown\", \"poutcome_unknown\"], axis=1)\n",
    "\n",
    "df['y'] = df_y\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df[\"default\"] = le.fit_transform(df[\"default\"])\n",
    "df[\"housing\"] = le.fit_transform(df[\"housing\"])\n",
    "df[\"loan\"] = le.fit_transform(df[\"loan\"])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "\n",
    "x = df.iloc[:, 0:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=2, stratify=y)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "x_test = sc_X.transform(x_test)\n",
    "\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:, 0:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=2, stratify=y)\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "x_test = sc_X.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [{&#x27;no&#x27;: 1, &#x27;yes&#x27;: 3},\n",
       "                                                         {&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4},\n",
       "                                                         {&#x27;no&#x27;: 1, &#x27;yes&#x27;: 5}],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [11, 12, 13, 14, 15, 16,\n",
       "                                                      17],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [{&#x27;no&#x27;: 1, &#x27;yes&#x27;: 3},\n",
       "                                                         {&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4},\n",
       "                                                         {&#x27;no&#x27;: 1, &#x27;yes&#x27;: 5}],\n",
       "                                        &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
       "                                                      &#x27;log_loss&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [11, 12, 13, 14, 15, 16,\n",
       "                                                      17],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'class_weight': [{'no': 1, 'yes': 3},\n",
       "                                                         {'no': 1, 'yes': 4},\n",
       "                                                         {'no': 1, 'yes': 5}],\n",
       "                                        'criterion': ['gini', 'entropy',\n",
       "                                                      'log_loss'],\n",
       "                                        'max_depth': [11, 12, 13, 14, 15, 16,\n",
       "                                                      17],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                                        'min_samples_split': [2, 3, 4, 5]},\n",
       "                   scoring='roc_auc', verbose=4)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search_space = {}\n",
    "search_space[\"criterion\"] = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "search_space[\"max_depth\"] = [11, 12, 13, 14, 15, 16, 17]\n",
    "search_space[\"min_samples_split\"] = [2, 3, 4, 5]\n",
    "search_space[\"min_samples_leaf\"] = [1, 2, 3, 4, 5]\n",
    "search_space[\"class_weight\"] = [{'no':1, 'yes':3}, {'no':1, 'yes':4}, {'no':1, 'yes':5}]\n",
    "\n",
    "model = RandomizedSearchCV(estimator=DecisionTreeClassifier(), param_distributions=search_space, scoring=\"roc_auc\", n_iter=50, cv=5, verbose=4, n_jobs=-1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight={&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4}, max_depth=14,\n",
       "                       min_samples_leaf=3, min_samples_split=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight={&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4}, max_depth=14,\n",
       "                       min_samples_leaf=3, min_samples_split=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(class_weight={'no': 1, 'yes': 4}, max_depth=14,\n",
       "                       min_samples_leaf=3, min_samples_split=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(class_weight={'no': 1, 'yes': 4}, max_depth=14, min_samples_leaf=3, min_samples_split=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight={'no': 1, 'yes': 5}, criterion='log_loss',\n",
      "                       max_depth=10, min_samples_leaf=5, min_samples_split=3)\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, x_test, y_test, scoring='roc_auc', cv=5)\n",
    "\n",
    "x_pred = model.predict(x_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74637904, 0.66523519, 0.75561878, 0.7391924 , 0.69707407])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.98      0.92      0.95     29941\n",
      "         yes       0.61      0.88      0.72      3967\n",
      "\n",
      "    accuracy                           0.92     33908\n",
      "   macro avg       0.80      0.90      0.84     33908\n",
      "weighted avg       0.94      0.92      0.93     33908\n",
      "\n",
      "[[27686  2255]\n",
      " [  465  3502]]\n",
      "test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.95      0.90      0.92      9981\n",
      "         yes       0.47      0.67      0.55      1322\n",
      "\n",
      "    accuracy                           0.87     11303\n",
      "   macro avg       0.71      0.78      0.74     11303\n",
      "weighted avg       0.90      0.87      0.88     11303\n",
      "\n",
      "[[8964 1017]\n",
      " [ 437  885]]\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\")\n",
    "\n",
    "print(classification_report(y_train, x_pred))\n",
    "\n",
    "print(confusion_matrix(y_train, x_pred))\n",
    "\n",
    "print(\"test data:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Iteration 1, loss = 0.51594319\n",
      "Iteration 2, loss = 0.39221377\n",
      "Iteration 3, loss = 0.38136612\n",
      "Iteration 4, loss = 0.37635220\n",
      "Iteration 5, loss = 0.37351356\n",
      "Iteration 6, loss = 0.36623260\n",
      "Iteration 7, loss = 0.36140117\n",
      "Iteration 8, loss = 0.35331997\n",
      "Iteration 9, loss = 0.34820011\n",
      "Iteration 10, loss = 0.34284292\n",
      "Iteration 11, loss = 0.33766480\n",
      "Iteration 12, loss = 0.33232989\n",
      "Iteration 13, loss = 0.32849097\n",
      "Iteration 14, loss = 0.32544471\n",
      "Iteration 15, loss = 0.32252337\n",
      "Iteration 16, loss = 0.31877985\n",
      "Iteration 17, loss = 0.31780148\n",
      "Iteration 18, loss = 0.31350839\n",
      "Iteration 19, loss = 0.31182037\n",
      "Iteration 20, loss = 0.31027269\n",
      "Iteration 21, loss = 0.30763983\n",
      "Iteration 22, loss = 0.30525636\n",
      "Iteration 23, loss = 0.30388492\n",
      "Iteration 24, loss = 0.30133427\n",
      "Iteration 25, loss = 0.30025794\n",
      "Iteration 26, loss = 0.29922407\n",
      "Iteration 27, loss = 0.29648528\n",
      "Iteration 28, loss = 0.29498465\n",
      "Iteration 29, loss = 0.29424738\n",
      "Iteration 30, loss = 0.29083273\n",
      "Iteration 31, loss = 0.29085001\n",
      "Iteration 32, loss = 0.28888651\n",
      "Iteration 33, loss = 0.28799011\n",
      "Iteration 34, loss = 0.28523279\n",
      "Iteration 35, loss = 0.28492831\n",
      "Iteration 36, loss = 0.28289399\n",
      "Iteration 37, loss = 0.28165598\n",
      "Iteration 38, loss = 0.28130236\n",
      "Iteration 39, loss = 0.27994316\n",
      "Iteration 40, loss = 0.27848917\n",
      "Iteration 41, loss = 0.27816773\n",
      "Iteration 42, loss = 0.27672688\n",
      "Iteration 43, loss = 0.27523977\n",
      "Iteration 44, loss = 0.27400743\n",
      "Iteration 45, loss = 0.27345201\n",
      "Iteration 46, loss = 0.27165012\n",
      "Iteration 47, loss = 0.27125266\n",
      "Iteration 48, loss = 0.26912773\n",
      "Iteration 49, loss = 0.26989229\n",
      "Iteration 50, loss = 0.26874613\n",
      "Iteration 51, loss = 0.26661518\n",
      "Iteration 52, loss = 0.26690068\n",
      "Iteration 53, loss = 0.26672408\n",
      "Iteration 54, loss = 0.26542764\n",
      "Iteration 55, loss = 0.26560832\n",
      "Iteration 56, loss = 0.26434991\n",
      "Iteration 57, loss = 0.26376067\n",
      "Iteration 58, loss = 0.26546551\n",
      "Iteration 59, loss = 0.26276750\n",
      "Iteration 60, loss = 0.26212064\n",
      "Iteration 61, loss = 0.26244244\n",
      "Iteration 62, loss = 0.26172036\n",
      "Iteration 63, loss = 0.26146139\n",
      "Iteration 64, loss = 0.25977615\n",
      "Iteration 65, loss = 0.26019274\n",
      "Iteration 66, loss = 0.26100853\n",
      "Iteration 67, loss = 0.25962069\n",
      "Iteration 68, loss = 0.25992635\n",
      "Iteration 69, loss = 0.25784978\n",
      "Iteration 70, loss = 0.25764610\n",
      "Iteration 71, loss = 0.25818233\n",
      "Iteration 72, loss = 0.25821975\n",
      "Iteration 73, loss = 0.25897283\n",
      "Iteration 74, loss = 0.25684110\n",
      "Iteration 75, loss = 0.25589635\n",
      "Iteration 76, loss = 0.25597698\n",
      "Iteration 77, loss = 0.25626951\n",
      "Iteration 78, loss = 0.25742005\n",
      "Iteration 79, loss = 0.25506941\n",
      "Iteration 80, loss = 0.25598691\n",
      "Iteration 81, loss = 0.25614400\n",
      "Iteration 82, loss = 0.25424831\n",
      "Iteration 83, loss = 0.25486910\n",
      "Iteration 84, loss = 0.25451739\n",
      "Iteration 85, loss = 0.25387899\n",
      "Iteration 86, loss = 0.25393636\n",
      "Iteration 87, loss = 0.25290785\n",
      "Iteration 88, loss = 0.25375273\n",
      "Iteration 89, loss = 0.25262072\n",
      "Iteration 90, loss = 0.25279572\n",
      "Iteration 91, loss = 0.25320834\n",
      "Iteration 92, loss = 0.25233900\n",
      "Iteration 93, loss = 0.25336210\n",
      "Iteration 94, loss = 0.25161471\n",
      "Iteration 95, loss = 0.25262692\n",
      "Iteration 96, loss = 0.25246468\n",
      "Iteration 97, loss = 0.25255541\n",
      "Iteration 98, loss = 0.25220551\n",
      "Iteration 99, loss = 0.25163848\n",
      "Iteration 100, loss = 0.25175376\n",
      "Iteration 101, loss = 0.24999641\n",
      "Iteration 102, loss = 0.25088212\n",
      "Iteration 103, loss = 0.25061528\n",
      "Iteration 104, loss = 0.25023907\n",
      "Iteration 105, loss = 0.25156706\n",
      "Iteration 106, loss = 0.24974739\n",
      "Iteration 107, loss = 0.25010553\n",
      "Iteration 108, loss = 0.25038083\n",
      "Iteration 109, loss = 0.24960320\n",
      "Iteration 110, loss = 0.24988210\n",
      "Iteration 111, loss = 0.24876164\n",
      "Iteration 112, loss = 0.24979192\n",
      "Iteration 113, loss = 0.24928539\n",
      "Iteration 114, loss = 0.24940759\n",
      "Iteration 115, loss = 0.24954986\n",
      "Iteration 116, loss = 0.25099094\n",
      "Iteration 117, loss = 0.24969889\n",
      "Iteration 118, loss = 0.24773668\n",
      "Iteration 119, loss = 0.24957107\n",
      "Iteration 120, loss = 0.24817008\n",
      "Iteration 121, loss = 0.24826348\n",
      "Iteration 122, loss = 0.24957270\n",
      "Iteration 123, loss = 0.24843649\n",
      "Iteration 124, loss = 0.24843921\n",
      "Iteration 125, loss = 0.24677141\n",
      "Iteration 126, loss = 0.24852816\n",
      "Iteration 127, loss = 0.24803464\n",
      "Iteration 128, loss = 0.24906197\n",
      "Iteration 129, loss = 0.24806540\n",
      "Iteration 130, loss = 0.24884721\n",
      "Iteration 131, loss = 0.24750924\n",
      "Iteration 132, loss = 0.24865704\n",
      "Iteration 133, loss = 0.24799872\n",
      "Iteration 134, loss = 0.24703584\n",
      "Iteration 135, loss = 0.24952055\n",
      "Iteration 136, loss = 0.24836069\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=MLPClassifier(max_iter=500, verbose=4),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;,\n",
       "                                                       &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87D1B0&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [50],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;learning_rate_init&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E110&gt;,\n",
       "                                        &#x27;power_t&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E830&gt;},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=MLPClassifier(max_iter=500, verbose=4),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;identity&#x27;, &#x27;logistic&#x27;,\n",
       "                                                       &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87D1B0&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [50],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;learning_rate_init&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E110&gt;,\n",
       "                                        &#x27;power_t&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E830&gt;},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=500, verbose=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=500, verbose=4)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(max_iter=500, verbose=4),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['identity', 'logistic',\n",
       "                                                       'tanh', 'relu'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87D1B0>,\n",
       "                                        'hidden_layer_sizes': [50],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'learning_rate_init': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E110>,\n",
       "                                        'power_t': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001CCDD87E830>},\n",
       "                   scoring='roc_auc', verbose=4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "search_space = {}\n",
    "search_space[\"hidden_layer_sizes\"] = [(50)]\n",
    "search_space[\"activation\"] = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "search_space[\"alpha\"] = sp.stats.uniform(scale=1)\n",
    "search_space[\"learning_rate_init\"] = sp.stats.uniform(scale=1)\n",
    "search_space[\"power_t\"] = sp.stats.uniform(scale=1)\n",
    "search_space[\"learning_rate\"] = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "model = RandomizedSearchCV(estimator=MLPClassifier(verbose=4, max_iter=500), param_distributions=search_space, scoring=\"roc_auc\", n_iter=50, cv=5, verbose=4, n_jobs=-1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.45631576\n",
      "Iteration 2, loss = 0.39054083\n",
      "Iteration 3, loss = 0.38347699\n",
      "Iteration 4, loss = 0.37522366\n",
      "Iteration 5, loss = 0.37345689\n",
      "Iteration 6, loss = 0.37173055\n",
      "Iteration 7, loss = 0.36923162\n",
      "Iteration 8, loss = 0.36915543\n",
      "Iteration 9, loss = 0.36921685\n",
      "Iteration 10, loss = 0.36746064\n",
      "Iteration 11, loss = 0.36645698\n",
      "Iteration 12, loss = 0.36692255\n",
      "Iteration 13, loss = 0.36578781\n",
      "Iteration 14, loss = 0.36595427\n",
      "Iteration 15, loss = 0.36448033\n",
      "Iteration 16, loss = 0.36515857\n",
      "Iteration 17, loss = 0.36452659\n",
      "Iteration 18, loss = 0.36296931\n",
      "Iteration 19, loss = 0.36316163\n",
      "Iteration 20, loss = 0.36440479\n",
      "Iteration 21, loss = 0.36427413\n",
      "Iteration 22, loss = 0.36518225\n",
      "Iteration 23, loss = 0.36313855\n",
      "Iteration 24, loss = 0.36351762\n",
      "Iteration 25, loss = 0.36419330\n",
      "Iteration 26, loss = 0.36295066\n",
      "Iteration 27, loss = 0.36333232\n",
      "Iteration 28, loss = 0.36367586\n",
      "Iteration 29, loss = 0.36318217\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.19648334664868272, hidden_layer_sizes=50,\n",
       "              learning_rate_init=0.010003688668307698, max_iter=500,\n",
       "              power_t=0.746254516169116, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.19648334664868272, hidden_layer_sizes=50,\n",
       "              learning_rate_init=0.010003688668307698, max_iter=500,\n",
       "              power_t=0.746254516169116, verbose=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.19648334664868272, hidden_layer_sizes=50,\n",
       "              learning_rate_init=0.010003688668307698, max_iter=500,\n",
       "              power_t=0.746254516169116, verbose=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(alpha=0.19648334664868272, hidden_layer_sizes=(50),\n",
    "              learning_rate_init=0.010003688668307698, max_iter=500,\n",
    "              power_t=0.746254516169116, verbose=4)\n",
    "\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37634137\n",
      "Iteration 2, loss = 0.31121645\n",
      "Iteration 3, loss = 0.29401055\n",
      "Iteration 4, loss = 0.28328863\n",
      "Iteration 5, loss = 0.27660394\n",
      "Iteration 6, loss = 0.26909904\n",
      "Iteration 7, loss = 0.26630976\n",
      "Iteration 8, loss = 0.26311968\n",
      "Iteration 9, loss = 0.26363617\n",
      "Iteration 10, loss = 0.26066846\n",
      "Iteration 11, loss = 0.25802829\n",
      "Iteration 12, loss = 0.25835628\n",
      "Iteration 13, loss = 0.25729584\n",
      "Iteration 14, loss = 0.25780031\n",
      "Iteration 15, loss = 0.25833212\n",
      "Iteration 16, loss = 0.25758104\n",
      "Iteration 17, loss = 0.25503644\n",
      "Iteration 18, loss = 0.25359342\n",
      "Iteration 19, loss = 0.25296954\n",
      "Iteration 20, loss = 0.25232540\n",
      "Iteration 21, loss = 0.25483568\n",
      "Iteration 22, loss = 0.25249192\n",
      "Iteration 23, loss = 0.25203944\n",
      "Iteration 24, loss = 0.24984460\n",
      "Iteration 25, loss = 0.25347881\n",
      "Iteration 26, loss = 0.25352342\n",
      "Iteration 27, loss = 0.25065410\n",
      "Iteration 28, loss = 0.25056428\n",
      "Iteration 29, loss = 0.25177286\n",
      "Iteration 30, loss = 0.24925846\n",
      "Iteration 31, loss = 0.24952713\n",
      "Iteration 32, loss = 0.25002929\n",
      "Iteration 33, loss = 0.25131870\n",
      "Iteration 34, loss = 0.24828593\n",
      "Iteration 35, loss = 0.24882047\n",
      "Iteration 36, loss = 0.25062471\n",
      "Iteration 37, loss = 0.24850281\n",
      "Iteration 38, loss = 0.24891789\n",
      "Iteration 39, loss = 0.24903118\n",
      "Iteration 40, loss = 0.24644770\n",
      "Iteration 41, loss = 0.25063924\n",
      "Iteration 42, loss = 0.24996144\n",
      "Iteration 43, loss = 0.25209463\n",
      "Iteration 44, loss = 0.24834299\n",
      "Iteration 45, loss = 0.24936082\n",
      "Iteration 46, loss = 0.24921184\n",
      "Iteration 47, loss = 0.24898700\n",
      "Iteration 48, loss = 0.24830924\n",
      "Iteration 49, loss = 0.24842614\n",
      "Iteration 50, loss = 0.24798665\n",
      "Iteration 51, loss = 0.24908559\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.37606940\n",
      "Iteration 2, loss = 0.31013727\n",
      "Iteration 3, loss = 0.29358195\n",
      "Iteration 4, loss = 0.28559131\n",
      "Iteration 5, loss = 0.27435370\n",
      "Iteration 6, loss = 0.26952332\n",
      "Iteration 7, loss = 0.26948000\n",
      "Iteration 8, loss = 0.26371365\n",
      "Iteration 9, loss = 0.26114766\n",
      "Iteration 10, loss = 0.26172319\n",
      "Iteration 11, loss = 0.26360553\n",
      "Iteration 12, loss = 0.25987447\n",
      "Iteration 13, loss = 0.26055182\n",
      "Iteration 14, loss = 0.25565365\n",
      "Iteration 15, loss = 0.25495077\n",
      "Iteration 16, loss = 0.25587254\n",
      "Iteration 17, loss = 0.25409914\n",
      "Iteration 18, loss = 0.25678695\n",
      "Iteration 19, loss = 0.25351955\n",
      "Iteration 20, loss = 0.25235642\n",
      "Iteration 21, loss = 0.25600611\n",
      "Iteration 22, loss = 0.25182748\n",
      "Iteration 23, loss = 0.25084014\n",
      "Iteration 24, loss = 0.25062851\n",
      "Iteration 25, loss = 0.25156701\n",
      "Iteration 26, loss = 0.25378225\n",
      "Iteration 27, loss = 0.24789638\n",
      "Iteration 28, loss = 0.25137828\n",
      "Iteration 29, loss = 0.25110511\n",
      "Iteration 30, loss = 0.25519526\n",
      "Iteration 31, loss = 0.25134620\n",
      "Iteration 32, loss = 0.24905579\n",
      "Iteration 33, loss = 0.25011882\n",
      "Iteration 34, loss = 0.24994383\n",
      "Iteration 35, loss = 0.25045483\n",
      "Iteration 36, loss = 0.25012635\n",
      "Iteration 37, loss = 0.25345186\n",
      "Iteration 38, loss = 0.25108874\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38125008\n",
      "Iteration 2, loss = 0.30928282\n",
      "Iteration 3, loss = 0.29047034\n",
      "Iteration 4, loss = 0.27924315\n",
      "Iteration 5, loss = 0.27527245\n",
      "Iteration 6, loss = 0.26796525\n",
      "Iteration 7, loss = 0.26403634\n",
      "Iteration 8, loss = 0.26311721\n",
      "Iteration 9, loss = 0.26129438\n",
      "Iteration 10, loss = 0.25731683\n",
      "Iteration 11, loss = 0.26254074\n",
      "Iteration 12, loss = 0.25957748\n",
      "Iteration 13, loss = 0.25508600\n",
      "Iteration 14, loss = 0.25528961\n",
      "Iteration 15, loss = 0.25899103\n",
      "Iteration 16, loss = 0.25417951\n",
      "Iteration 17, loss = 0.25300086\n",
      "Iteration 18, loss = 0.25266025\n",
      "Iteration 19, loss = 0.25276402\n",
      "Iteration 20, loss = 0.25103050\n",
      "Iteration 21, loss = 0.25127230\n",
      "Iteration 22, loss = 0.25018881\n",
      "Iteration 23, loss = 0.25176995\n",
      "Iteration 24, loss = 0.25139569\n",
      "Iteration 25, loss = 0.24996353\n",
      "Iteration 26, loss = 0.25055831\n",
      "Iteration 27, loss = 0.24850592\n",
      "Iteration 28, loss = 0.25089278\n",
      "Iteration 29, loss = 0.25109610\n",
      "Iteration 30, loss = 0.24813414\n",
      "Iteration 31, loss = 0.24949013\n",
      "Iteration 32, loss = 0.24712154\n",
      "Iteration 33, loss = 0.24984806\n",
      "Iteration 34, loss = 0.25027577\n",
      "Iteration 35, loss = 0.25137140\n",
      "Iteration 36, loss = 0.24821532\n",
      "Iteration 37, loss = 0.25104555\n",
      "Iteration 38, loss = 0.24738817\n",
      "Iteration 39, loss = 0.24897566\n",
      "Iteration 40, loss = 0.24811239\n",
      "Iteration 41, loss = 0.24967287\n",
      "Iteration 42, loss = 0.24931043\n",
      "Iteration 43, loss = 0.24925998\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38880072\n",
      "Iteration 2, loss = 0.31543991\n",
      "Iteration 3, loss = 0.29984729\n",
      "Iteration 4, loss = 0.29373687\n",
      "Iteration 5, loss = 0.28372251\n",
      "Iteration 6, loss = 0.27668122\n",
      "Iteration 7, loss = 0.27360680\n",
      "Iteration 8, loss = 0.26974829\n",
      "Iteration 9, loss = 0.26951108\n",
      "Iteration 10, loss = 0.27086141\n",
      "Iteration 11, loss = 0.26830238\n",
      "Iteration 12, loss = 0.26429849\n",
      "Iteration 13, loss = 0.26185159\n",
      "Iteration 14, loss = 0.26050319\n",
      "Iteration 15, loss = 0.26414507\n",
      "Iteration 16, loss = 0.26143686\n",
      "Iteration 17, loss = 0.26321401\n",
      "Iteration 18, loss = 0.26567880\n",
      "Iteration 19, loss = 0.26477532\n",
      "Iteration 20, loss = 0.25991892\n",
      "Iteration 21, loss = 0.25780539\n",
      "Iteration 22, loss = 0.25945748\n",
      "Iteration 23, loss = 0.25587868\n",
      "Iteration 24, loss = 0.25677881\n",
      "Iteration 25, loss = 0.25700440\n",
      "Iteration 26, loss = 0.25687419\n",
      "Iteration 27, loss = 0.25893327\n",
      "Iteration 28, loss = 0.25546627\n",
      "Iteration 29, loss = 0.25614933\n",
      "Iteration 30, loss = 0.25507673\n",
      "Iteration 31, loss = 0.25508081\n",
      "Iteration 32, loss = 0.25449250\n",
      "Iteration 33, loss = 0.25439764\n",
      "Iteration 34, loss = 0.25511278\n",
      "Iteration 35, loss = 0.25453736\n",
      "Iteration 36, loss = 0.25439670\n",
      "Iteration 37, loss = 0.25515536\n",
      "Iteration 38, loss = 0.25543068\n",
      "Iteration 39, loss = 0.25537790\n",
      "Iteration 40, loss = 0.25404665\n",
      "Iteration 41, loss = 0.25489022\n",
      "Iteration 42, loss = 0.25682393\n",
      "Iteration 43, loss = 0.25479467\n",
      "Iteration 44, loss = 0.25642817\n",
      "Iteration 45, loss = 0.25620414\n",
      "Iteration 46, loss = 0.25507092\n",
      "Iteration 47, loss = 0.25521072\n",
      "Iteration 48, loss = 0.25463988\n",
      "Iteration 49, loss = 0.25257973\n",
      "Iteration 50, loss = 0.25248095\n",
      "Iteration 51, loss = 0.25353702\n",
      "Iteration 52, loss = 0.25381603\n",
      "Iteration 53, loss = 0.25300181\n",
      "Iteration 54, loss = 0.25215082\n",
      "Iteration 55, loss = 0.25259786\n",
      "Iteration 56, loss = 0.25078711\n",
      "Iteration 57, loss = 0.25556173\n",
      "Iteration 58, loss = 0.25412504\n",
      "Iteration 59, loss = 0.25542681\n",
      "Iteration 60, loss = 0.25251216\n",
      "Iteration 61, loss = 0.25812198\n",
      "Iteration 62, loss = 0.25538846\n",
      "Iteration 63, loss = 0.25182739\n",
      "Iteration 64, loss = 0.25079172\n",
      "Iteration 65, loss = 0.25187419\n",
      "Iteration 66, loss = 0.25224413\n",
      "Iteration 67, loss = 0.25108111\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38819832\n",
      "Iteration 2, loss = 0.31183065\n",
      "Iteration 3, loss = 0.29451174\n",
      "Iteration 4, loss = 0.28113720\n",
      "Iteration 5, loss = 0.27477293\n",
      "Iteration 6, loss = 0.27199518\n",
      "Iteration 7, loss = 0.26907871\n",
      "Iteration 8, loss = 0.26420232\n",
      "Iteration 9, loss = 0.26376026\n",
      "Iteration 10, loss = 0.26409416\n",
      "Iteration 11, loss = 0.25950305\n",
      "Iteration 12, loss = 0.25893831\n",
      "Iteration 13, loss = 0.26017205\n",
      "Iteration 14, loss = 0.26441447\n",
      "Iteration 15, loss = 0.25901171\n",
      "Iteration 16, loss = 0.25944267\n",
      "Iteration 17, loss = 0.25728616\n",
      "Iteration 18, loss = 0.25447991\n",
      "Iteration 19, loss = 0.25503552\n",
      "Iteration 20, loss = 0.25694833\n",
      "Iteration 21, loss = 0.25633485\n",
      "Iteration 22, loss = 0.25678583\n",
      "Iteration 23, loss = 0.25584239\n",
      "Iteration 24, loss = 0.25345513\n",
      "Iteration 25, loss = 0.25553963\n",
      "Iteration 26, loss = 0.25206157\n",
      "Iteration 27, loss = 0.25382695\n",
      "Iteration 28, loss = 0.25148751\n",
      "Iteration 29, loss = 0.25302430\n",
      "Iteration 30, loss = 0.25819764\n",
      "Iteration 31, loss = 0.25273861\n",
      "Iteration 32, loss = 0.25134518\n",
      "Iteration 33, loss = 0.25228172\n",
      "Iteration 34, loss = 0.25086836\n",
      "Iteration 35, loss = 0.25302096\n",
      "Iteration 36, loss = 0.25271823\n",
      "Iteration 37, loss = 0.25097896\n",
      "Iteration 38, loss = 0.25220993\n",
      "Iteration 39, loss = 0.25114172\n",
      "Iteration 40, loss = 0.25430354\n",
      "Iteration 41, loss = 0.25179916\n",
      "Iteration 42, loss = 0.25345221\n",
      "Iteration 43, loss = 0.25274114\n",
      "Iteration 44, loss = 0.25296870\n",
      "Iteration 45, loss = 0.25491523\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, x_test, y_test, scoring='roc_auc', cv=5)\n",
    "\n",
    "x_pred = model.predict(x_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90180915, 0.89787121, 0.90183953, 0.91855302, 0.92183989])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.86      0.88     29941\n",
      "         yes       0.87      0.90      0.88     29941\n",
      "\n",
      "    accuracy                           0.88     59882\n",
      "   macro avg       0.88      0.88      0.88     59882\n",
      "weighted avg       0.88      0.88      0.88     59882\n",
      "\n",
      "[[25873  4068]\n",
      " [ 3013 26928]]\n",
      "test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.98      0.87      0.92      9981\n",
      "         yes       0.46      0.83      0.59      1322\n",
      "\n",
      "    accuracy                           0.86     11303\n",
      "   macro avg       0.72      0.85      0.75     11303\n",
      "weighted avg       0.91      0.86      0.88     11303\n",
      "\n",
      "[[8670 1311]\n",
      " [ 222 1100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\")\n",
    "\n",
    "print(classification_report(y_train, x_pred))\n",
    "\n",
    "print(confusion_matrix(y_train, x_pred))\n",
    "\n",
    "print(\"test data:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mbest_estimator_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(break_ties=True, class_weight={&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(break_ties=True, class_weight={&#x27;no&#x27;: 1, &#x27;yes&#x27;: 4})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(break_ties=True, class_weight={'no': 1, 'yes': 4})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\" : [0.1, 1, 10],\n",
    "    \"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"class_weight\" : [{'no':1, 'yes':2}, {'no':1, 'yes':4}, {'no':1, 'yes':5}]\n",
    "    }\n",
    "\n",
    "param_grid = {'break_ties' : [True, False]}\n",
    "\n",
    "model = GridSearchCV(estimator=SVC(class_weight={'no':1, 'yes':4}), param_grid=param_grid, refit=True, scoring=\"f1\", cv=2, verbose=2, n_jobs=-1)\n",
    "model = SVC(class_weight={'no':1, 'yes':4}, break_ties=True)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(break_ties=True, class_weight={'no': 1, 'yes': 4})\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, x_test, y_test, scoring='roc_auc', cv=5)\n",
    "\n",
    "x_pred = model.predict(x_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88678472, 0.90640715, 0.89077778, 0.90611906, 0.91095259])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.91      0.94     29941\n",
      "         yes       0.55      0.82      0.66      3967\n",
      "\n",
      "    accuracy                           0.90     33908\n",
      "   macro avg       0.76      0.87      0.80     33908\n",
      "weighted avg       0.92      0.90      0.91     33908\n",
      "\n",
      "[[27236  2705]\n",
      " [  711  3256]]\n",
      "test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.91      0.93      9981\n",
      "         yes       0.51      0.73      0.60      1322\n",
      "\n",
      "    accuracy                           0.89     11303\n",
      "   macro avg       0.74      0.82      0.77     11303\n",
      "weighted avg       0.91      0.89      0.89     11303\n",
      "\n",
      "[[9053  928]\n",
      " [ 359  963]]\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\")\n",
    "\n",
    "print(classification_report(y_train, x_pred))\n",
    "\n",
    "print(confusion_matrix(y_train, x_pred))\n",
    "\n",
    "print(\"test data:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420a72a87379193fe07b10ca7648dce266aa0071bb0c0efc03aee74a2307b1ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
